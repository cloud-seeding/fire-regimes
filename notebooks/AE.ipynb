{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import decomposition\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('~/Desktop/columbia/capstone/fire-regimes/data/merged_output.csv').drop(columns=['id1','id2','time','x','y'])\n",
    "\n",
    "df_dedup = data.groupby(['source_file','level'], as_index=False).mean()\n",
    "df_pivoted = df_dedup.set_index(['source_file', 'level']).unstack('level')\n",
    "df_pivoted.columns = [f'{level}-{var}' for var, level in df_pivoted.columns]\n",
    "\n",
    "X = df_pivoted[~np.isnan(df_pivoted).any(axis=1)]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in data for torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.from_numpy(X).float()\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An AutoEncoder Class with dynamic latent dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(torch.nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(174, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, latent_dim)  # Use latent_dim here\n",
    "        )\n",
    "         \n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(latent_dim, 64),  # Start with latent_dim here\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, 174)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder(latent_dim=12)\n",
    " \n",
    "# Validation using MSE Loss function\n",
    "loss_function = torch.nn.MSELoss()\n",
    " \n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr = 0.01,\n",
    "                             weight_decay = 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,n_epochs):\n",
    "\n",
    "  losses = []\n",
    "\n",
    "  for _ in range(n_epochs):\n",
    "    for profile in train_loader:\n",
    "        \n",
    "      # Output of Autoencoder\n",
    "      reconstructed = model(profile)\n",
    "        \n",
    "      # Calculating the loss function\n",
    "      loss = loss_function(reconstructed, profile)\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "        \n",
    "      losses.append(loss)\n",
    "  \n",
    "  return (model,losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_average(data, window_size):\n",
    "    return np.convolve(data, np.ones(window_size) / window_size, mode='valid')\n",
    "\n",
    "def plot_loss(losses,window_size):\n",
    "    loss_floats = [loss.item() for loss in losses]\n",
    "    smoothed_losses = rolling_average(loss_floats, window_size)\n",
    "    plt.plot(smoothed_losses)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,losses = train_model(model,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(losses=losses,window_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = model(train_data).detach().numpy()\n",
    "train = train_data.numpy()\n",
    "l = model.encoder(train_data).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, random_state=1)\n",
    "X_tsne = tsne.fit_transform(l)\n",
    "\n",
    "plt.scatter(X_tsne[:, 0], X_tsne[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('latent.npy',l)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
